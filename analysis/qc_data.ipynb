{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopping_data(df, split_by_block_num=False):\n",
    "    \"\"\"\n",
    "    Extracts and calculates metrics related to 'stop' and 'go' conditions for test trials.\n",
    "    \n",
    "    The function processes data to compute key metrics, including accuracy, response time (rt),\n",
    "    stop signal delay (SSD), and omission rates, for both 'stop' and 'go' trial conditions.\n",
    "    The results can be grouped by block numbers if required.\n",
    "    \n",
    "    Input:\n",
    "      df: DataFrame containing the trial data.\n",
    "      split_by_block_num (optional): Boolean flag to determine if results should be grouped \n",
    "      by block number (default is False).\n",
    "      \n",
    "    Output:\n",
    "      Prints the computed metrics either grouped by block numbers or in an aggregated form.\n",
    "      \n",
    "    Metrics Calculated:\n",
    "      - stop_acc: Mean accuracy for 'stop' trials.\n",
    "      - go_acc: Mean accuracy for 'go' trials.\n",
    "      - avg_go_rt: Average response time for correct 'go' trials.\n",
    "      - max_SSD: Maximum stop signal delay.\n",
    "      - min_SSD: Minimum stop signal delay.\n",
    "      - mean_SSD: Average stop signal delay.\n",
    "      - stop_success: Percentage of successful stops.\n",
    "      - stop_fail: Percentage of failed stops.\n",
    "      - go_success: Percentage of successful 'go' trials.\n",
    "      - stop_omission_rate: Omission rate for 'stop' trials.\n",
    "      - go_omission_rate: Omission rate for 'go' trials.\n",
    "    \"\"\"\n",
    "    test_trials__df = df[(df['trial_id'] == 'test_trial')]\n",
    "    \n",
    "    grouping_column = 'block_num' if split_by_block_num else None\n",
    "\n",
    "    # If we're splitting by block_num, group the data by block_num\n",
    "    if split_by_block_num:\n",
    "        stop_trials = test_trials__df[(test_trials__df['condition'] == 'stop')].groupby(grouping_column)\n",
    "        go_trials = test_trials__df[(test_trials__df['condition'] == 'go')].groupby(grouping_column)\n",
    "    else:\n",
    "        stop_trials = test_trials__df[(test_trials__df['condition'] == 'stop')]\n",
    "        go_trials = test_trials__df[(test_trials__df['condition'] == 'go')]\n",
    "\n",
    "    # Define a helper function to calculate metrics for a given group\n",
    "    def calculate_metrics(group):\n",
    "        stop_acc = group[group['condition'] == 'stop']['stop_acc'].mean()\n",
    "        go_acc = group[group['condition'] == 'go']['go_acc'].mean()\n",
    "\n",
    "        go_correct_trials = group[(group['condition'] == 'go') & (group['go_acc'] == 1)]\n",
    "        avg_go_rt = go_correct_trials['rt'].mean()\n",
    "\n",
    "        max_SSD = group['SSD'].max()\n",
    "        min_SSD = group['SSD'].min()\n",
    "        mean_SSD = group['SSD'].mean()\n",
    "\n",
    "        stop_success = group[group['condition'] == 'stop']['stop_acc'].mean()\n",
    "        stop_fail = 1 - stop_success\n",
    "\n",
    "        go_success = group[group['condition'] == 'go']['go_acc'].mean()\n",
    "        stop_omission_rate = group[group['condition'] == 'stop']['rt'].isna().mean()\n",
    "        go_omission_rate = group[group['condition'] == 'go']['rt'].isna().mean()\n",
    "\n",
    "        return {\n",
    "            \"stop_acc\": stop_acc,\n",
    "            \"go_acc\": go_acc,\n",
    "            \"avg_go_rt\": avg_go_rt,\n",
    "            \"max_SSD\": max_SSD,\n",
    "            \"min_SSD\": min_SSD,\n",
    "            \"mean_SSD\": mean_SSD,\n",
    "            \"stop_success\": stop_success,\n",
    "            \"stop_fail\": stop_fail,\n",
    "            \"go_success\": go_success,\n",
    "            \"stop_omission_rate\": stop_omission_rate,\n",
    "            \"go_omission_rate\": go_omission_rate\n",
    "        }\n",
    "\n",
    "    # If we're splitting by block_num, apply the helper function to each group\n",
    "    if split_by_block_num:\n",
    "        results = test_trials__df.groupby(grouping_column).apply(calculate_metrics)\n",
    "        print(results)\n",
    "    else:\n",
    "        results = calculate_metrics(test_trials__df)\n",
    "        for key, value in results.items():\n",
    "            print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_rt(df, condition_col='condition', test_trial='test_trial', correct_trial_col='correct_trial', factorial_condition=False, factorial_conditions=['cue_condition', 'task_condition'], split_by_block_num=False):\n",
    "    \"\"\"\n",
    "    Calculates the average reaction time (RT) for given test trials based on specific conditions.\n",
    "    \n",
    "    This function can handle both standard conditions and factorial conditions. Additionally,\n",
    "    results can optionally be split by block number.\n",
    "    \n",
    "    Input:\n",
    "      df: DataFrame containing the experiment data.\n",
    "      condition_col: Name of the column representing the condition. Default is 'condition'.\n",
    "      test_trial: Name of the column indicating the type of trial. Default is 'test_trial'.\n",
    "      correct_trial_col: Column indicating if the trial was correctly executed. Default is 'correct_trial'.\n",
    "      factorial_condition: Boolean to specify if the data has factorial conditions. Default is False.\n",
    "      factorial_conditions: List of columns indicating factorial conditions. Default is ['cue_condition', 'task_condition'].\n",
    "      split_by_block_num: Boolean to specify if results should be split by block number. Default is False.\n",
    "    \n",
    "    Output:\n",
    "      Prints the average RT for the specified conditions.\n",
    "    \"\"\"    \n",
    "    test_trials__df = df[(df['trial_id'] == test_trial) & (df[correct_trial_col] == 1)]\n",
    "    \n",
    "    if factorial_condition:\n",
    "        grouping_columns = factorial_conditions\n",
    "    else:\n",
    "        grouping_columns = [condition_col]\n",
    "    \n",
    "    if split_by_block_num:\n",
    "        grouping_columns.append('block_num')\n",
    "    \n",
    "    rt_by_condition = test_trials__df.groupby(grouping_columns).apply(lambda group: group['rt'].mean())\n",
    "    print(rt_by_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_omission_rate(df, test_trial='test_trial', condition_col='condition', factorial_condition=False, factorial_conditions=['cue_condition', 'task_condition'], split_by_block_num=False):\n",
    "    \"\"\"\n",
    "    Calculates the omission rate for given test trials based on specific conditions.\n",
    "    \n",
    "    Omission rate refers to the proportion of missing reaction times (RTs) in the data. This function\n",
    "    supports calculations for both standard and factorial conditions. Results can optionally be split \n",
    "    by block number.\n",
    "    \n",
    "    Input:\n",
    "      df: DataFrame containing the experiment data.\n",
    "      test_trial: Name of the column indicating the type of trial. Default is 'test_trial'.\n",
    "      condition_col: Name of the column representing the condition. Default is 'condition'.\n",
    "      factorial_condition: Boolean to specify if the data has factorial conditions. Default is False.\n",
    "      factorial_conditions: List of columns indicating factorial conditions. Default is ['cue_condition', 'task_condition'].\n",
    "      split_by_block_num: Boolean to specify if results should be split by block number. Default is False.\n",
    "    \n",
    "    Output:\n",
    "      Prints the omission rate for the specified conditions.\n",
    "    \"\"\"\n",
    "     \n",
    "    test_trials__df = df[df['trial_id'] == test_trial]\n",
    "    \n",
    "    if factorial_condition:\n",
    "        grouping_columns = factorial_conditions\n",
    "    else:\n",
    "        grouping_columns = [condition_col]\n",
    "    \n",
    "    if split_by_block_num:\n",
    "        grouping_columns.append('block_num')\n",
    "    \n",
    "    omission_rate = test_trials__df.groupby(grouping_columns).apply(lambda group: group['rt'].isna().mean())\n",
    "    print(omission_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_omission_rate__span(df):\n",
    "    \"\"\"\n",
    "    Calculates the omission rate for the 'span' task based on specific trial types and response lengths.\n",
    "    \n",
    "    This function targets the 'span' task data to calculate two types of omissions: \n",
    "    1) Completely empty responses, and \n",
    "    2) Incomplete responses (i.e., responses with a length between 1 and 3).\n",
    "    \n",
    "    Additionally, this function calculates the omission rate for 'test_inter-stimulus' trials, \n",
    "    which is the proportion of missing reaction times (RTs) in these trials.\n",
    "\n",
    "    Input:\n",
    "      df: DataFrame containing the span task data.\n",
    "    \n",
    "    Output:\n",
    "      Prints the mean number of empty responses, the mean number of incomplete responses, \n",
    "      and the omission rate for 'test_inter-stimulus' trials.\n",
    "    \"\"\"\n",
    "    test_response_trials__df = df[df['trial_id'] == 'test_response'].copy()\n",
    "    test_processing_trials__df = df[df['trial_id'] == 'test_inter-stimulus']\n",
    "\n",
    "    # Convert the strings in the 'response' column to actual lists\n",
    "    test_response_trials__df['response'] = test_response_trials__df['response'].apply(ast.literal_eval)\n",
    "\n",
    "    omission_rate_processing_trials = test_processing_trials__df['rt'].isna().mean()\n",
    "\n",
    "    # Calculate the number of empty and incomplete responses\n",
    "    test_response_trials__df['empty'] = test_response_trials__df['response'].apply(lambda x: len(x) == 0)\n",
    "    test_response_trials__df['incomplete'] = test_response_trials__df['response'].apply(lambda x: 0 < len(x) < 4)\n",
    "\n",
    "    # Get the mean of each type\n",
    "    mean_empty = test_response_trials__df['empty'].mean()\n",
    "    mean_incomplete = test_response_trials__df['incomplete'].mean()\n",
    "\n",
    "    print(f\"Mean number of empty responses: {mean_empty}\")\n",
    "    print(f\"Mean number of incomplete responses: {mean_incomplete}\")\n",
    "\n",
    "    print(f\"Omission rate processing trials: {omission_rate_processing_trials}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_accuracy(df, correct_trial_col='correct_trial', condition_col='condition', test_trial='test_trial', factorial_condition=False, factorial_conditions=[], split_by_block_num=False):\n",
    "    \"\"\"\n",
    "    Calculates the average accuracy for given test trials based on specified conditions.\n",
    "    \n",
    "    This function computes the mean accuracy for a given set of test trials. It allows for grouping\n",
    "    by a single condition or multiple factorial conditions. The option to further split by block number\n",
    "    is also available. The accuracy is determined by averaging the values in the `correct_trial_col`.\n",
    "    \n",
    "    Input:\n",
    "      df: DataFrame containing the trial data.\n",
    "      correct_trial_col (optional): Name of the column indicating correct trials (default is 'correct_trial').\n",
    "      condition_col (optional): Name of the main condition column for grouping (default is 'condition').\n",
    "      test_trial (optional): Specifies the trial type to be considered for accuracy calculation (default is 'test_trial').\n",
    "      factorial_condition (optional): Boolean flag indicating if factorial conditions should be used for grouping (default is False).\n",
    "      factorial_conditions (optional): List of columns to be used for factorial grouping (default is an empty list).\n",
    "      split_by_block_num (optional): Boolean flag to determine if results should be split by block number (default is False).\n",
    "      \n",
    "    Output:\n",
    "      Prints the average accuracy grouped by the specified conditions.\n",
    "    \"\"\"\n",
    "   \n",
    "    test_trials__df = df[df['trial_id'] == test_trial]\n",
    "    \n",
    "    if factorial_condition:\n",
    "        grouping_columns = factorial_conditions\n",
    "    else:\n",
    "        grouping_columns = [condition_col]\n",
    "    \n",
    "    if split_by_block_num:\n",
    "        grouping_columns.append('block_num')\n",
    "    \n",
    "    accuracy_by_condition = test_trials__df.groupby(grouping_columns)[correct_trial_col].mean()\n",
    "    \n",
    "    print(accuracy_by_condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing sample data files for different RDoC tasks.\n",
    "\n",
    "ax_cpt__df = pd.read_csv('../ax_cpt_rdoc_23-10-25-16:51.json.csv') # probe trial\n",
    "cued_ts__df = pd.read_csv('../cued_task_switching_rdoc_23-10-25-17:36.json.csv') # factorial conditions, cue_condition & task_condition\n",
    "flanker__df = pd.read_csv('../flanker_rdoc_23-10-25-18:02.json.csv')\n",
    "go_nogo__df = pd.read_csv('../go_nogo_rdoc_23-10-25-18:20.json.csv')\n",
    "n_back__df = pd.read_csv('../n_back_rdoc_23-10-25-18:33.json.csv') # using delay instead\n",
    "span__df = pd.read_csv('../span_rdoc__behavioral_23-10-25-21:45.json.csv') \n",
    "spatial_ts__df = pd.read_csv('../spatial_task_switching_rdoc_23-10-25-20:33.json.csv')\n",
    "spatial_cueing__df = pd.read_csv('../spatial_cueing_rdoc_23-10-25-20:56.json.csv')\n",
    "stroop__df = pd.read_csv('../stroop_rdoc_23-10-25-18:44.json.csv')\n",
    "stop_signal__df = pd.read_csv('../stop_signal_rdoc_23-10-25-19:22.json.csv')\n",
    "visual_search__df = pd.read_csv('../visual_search_rdoc_23-10-25-19:10.json.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note about modifying function calls\n",
    "These are tasks that need slightly different arguments for accuracy, rt, and/or omission calculations:\n",
    "\n",
    "### ax-cpt\n",
    "```python\n",
    "calculate_average_accuracy(ax_cpt__df, test_trial='test_probe')  # need different test_trial than test_trial, must be test_probe instead\n",
    "```\n",
    "\n",
    "### cued ts\n",
    "```python \n",
    "calculate_average_accuracy(cued_ts__df, factorial_condition=True, factorial_conditions=['cue_condition', 'task_condition']) # need to use factorial for cue_condition and task_condition since separate cols\n",
    "```\n",
    "#### Note: Looks like we don't have to do this for spatial_ts since it already combines in the conditions (e.g. tstay_cstay) prior to exporting data. \n",
    "\n",
    "### nback  \n",
    "```python\n",
    "calculate_average_accuracy(n_back__df, condition_col='delay') # need to use delay instead of 'match' , 'mismatch' condition \n",
    "calculate_average_rt(n_back__df, condition_col='delay') # need to use delay instead of 'match' , 'mismatch' condition \n",
    "```\n",
    "\n",
    "### span (simple & operation; i.e. storage-only and same-domain)\n",
    "```python\n",
    "calculate_average_accuracy(span__df, test_trial='test_response')\n",
    "calculate_average_rt(span__df, test_trial='test_inter-stimulus', correct_trial_col='correct_response')\n",
    "calculate_omission_rate__span(span__df) # need something different for omissions since no response in test_response is [] and incomplete is [].length < 4\n",
    "```\n",
    "\n",
    "### stop signal\n",
    "```python\n",
    "get_stopping_data(stop_signal__df)\n",
    "```\n",
    "\n",
    "### visual search\n",
    "```python\n",
    "calculate_average_accuracy(visual_search__df, factorial_condition=True, factorial_conditions=['condition', 'num_stimuli']) # need to use factorial for load and feature/conjunction\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
